{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488fe87a",
   "metadata": {},
   "source": [
    "# High-Performance Analysis of Binary Systems Datasets with Dask\n",
    "\n",
    "Puggioni Dario, Salvador Alberto, Saran Gattorno Giancarlo, Volpi Gaia\n",
    "\n",
    "<span style=\"color:red\"> inserire numeri matricola</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b2777",
   "metadata": {},
   "source": [
    "# 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225fa09",
   "metadata": {},
   "source": [
    "`Write about the context of the processing task to be analyzed in this project (ie what is SEVN, what is data used for in astrophysics context, etc...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519a206-850c-4434-8744-f49508f4d174",
   "metadata": {},
   "source": [
    "The aim of this project is to analyize a dataset using the _Dask_ library for Python. The computation is optimized by using three virtual machines connected in a cluster. These virtual machines are provided by _CloudVeneto_, a cloud computing platform managed by the University of Padova.\\\n",
    "More specifically, we want to study the conditions that lead to the formation of a binary-black holes system that merge via Gravitational Waves emission.\n",
    "\n",
    "#### SEVN\n",
    "The data we are dealing with are provided by _SEVN_ (Stellar EVolution N-body), a software for simulating the evolution binary systems of stars.\\\n",
    "The evolution of a single star is univocally defined by its initial mass and metallicity, a parameter that refers to the abundance of elements heavier than Hydrogen and Helium in its atmosphere. \\\n",
    "The evolution of a binary system is determined by a series of processes that could happen between the two stars, and which depends on the initial proprierties of them. Some examples of such processes are: Wind-mass transfer, Super-Novae explosions, Common Envelope, Roche-Lobe Overflow, etc.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"immagini/sevn.jpg\" alt=\"Image\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd14de",
   "metadata": {},
   "source": [
    "# 2. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06728e9",
   "metadata": {},
   "source": [
    "`Write about the structure of the datasets here. Add diagrams/tables if useful`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18775740-165a-4577-8b8d-fa3baa051ca7",
   "metadata": {},
   "source": [
    "From SEVN we are able to retrieve the data describing the evolution of a given binary system. The dataset it returns is composed by a fixed amount of labels/columns, and a series of rows. Each row contains the values of the labels at a given time step. These time steps are not fixed as the evolution is performed with an 'adaptive time step' schema giving more time resolution where needed. Here it is the basic structure of a SEVN dataset:\n",
    "\n",
    "<span style=\"color:red\"> inserire head dataset per far vedere la struttura</span> \n",
    "\n",
    "We have at our disposal two datasets for two different metallicity:\n",
    "- Z=0.0014, the \"low metallicity\" dataset\n",
    "- Z=0.02, the \"high metallicity\" dataset\n",
    "\n",
    "Both of them shares the same structure that we discussed above.\n",
    "We will perform the same analysis on both and comparing the results to determine how the metallicity affect them.\n",
    "\n",
    "In a given dataset, we find multiple simulations of different binary systems, i.e., systems that starts with different physical proprieties. Typically the simulation of a single system goes on until the software detects that it reached a steady state (for example the two stars merged in a single one, one of the star exploded in a Super Novae, etc.). After a single simulation end, another simulation starts with a different initial conditions for the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28316c77",
   "metadata": {},
   "source": [
    "# 3. Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c49d2",
   "metadata": {},
   "source": [
    "`Describe briefly the setup of cluster and file system. Add diagrams if useful`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee759ce",
   "metadata": {},
   "source": [
    "The cluster consists of three CloudVeneto virtual machines. Each machine has 8GB RAM and 4 CPU cores (**check**).\n",
    "The cluster is created through ssh connections with rsa key identification allowing for passwordless communication. The three VMs are aliased as `scheduler` (ip 10.67.22.174), `worker1` (ip 10.67.22.36) and `worker2` (ip 10.67.22.251).\n",
    "\n",
    "Dask instantiates `Clients` from ssh-clusters through the method `dask.distributed.SSHCluster` which is based on the `paramiko` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is ran on the scheduler VM\n",
    "\n",
    "from dask.distributed import Client, SSHCluster\n",
    "\n",
    "cluster = SSHCluster(\n",
    "    [\"scheduler\", \"scheduler\", \"worker1\", \"worker2\"],\n",
    "    connect_options={\"known_hosts\":None},\n",
    "    scheduler_options={\"port\": 8786, \"dashboard_address\": \":8787\"}\n",
    ")\n",
    "\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcb8a3",
   "metadata": {},
   "source": [
    "In this configuration the virtual machine `scheduler` is both scheduler and worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60cc89",
   "metadata": {},
   "source": [
    "```\n",
    "Diagram of the dask network\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b85cf7",
   "metadata": {},
   "source": [
    "## 3.1 Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6bea2",
   "metadata": {},
   "source": [
    "The three VMs have 25GB of storage each, so the dataset has to be stored elsewhere. We opted for a 200GB volume from CloudVeneto. In order to share the data between all VMs we set up a distributed file system, in our case NFS. This is done by mounting the volume on one of the VMs (the NFS server), formatting it as Linux ext4 and then editing the `/etc/exports` file, which configures the ip addresses of the clients, their permissions and the level of consistency on write if clients are allowed to write on the distributed file system. In our case since we have no need to modify the data during processing we chose a configuration of the type\n",
    "```\n",
    "Paste etc/exports\n",
    "```\n",
    "Since the NFS server will also be a worker we had to exclude the scheduler, which would bottleneck the cluster performance if it had to take on all three roles.\n",
    "The datasets are then downloaded onto the volume from the Drive folder using `gdown`.\n",
    "```\n",
    "Diagram of the NFS network\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d76f8",
   "metadata": {},
   "source": [
    "# 4. Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070103b",
   "metadata": {},
   "source": [
    "## 4.1 Naive method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c081bd",
   "metadata": {},
   "source": [
    "`Method used for LCP-B before knowing Dask. Report performance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b58b5",
   "metadata": {},
   "source": [
    "## 4.2 Optimized method (bags? foldby? delay? etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf2f3d",
   "metadata": {},
   "source": [
    "`Optimize naive method as much as possible. Again report performance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb660d",
   "metadata": {},
   "source": [
    "## 4.3 (optional) File System behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85106138",
   "metadata": {},
   "source": [
    "`Try to understand the way dask and NFS handle data transfer, processing, etc... Especially considering that the NFS server is assigned some processing tasks and the scheduler is assigned processing tasks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72966401",
   "metadata": {},
   "source": [
    "# 5. Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c1708",
   "metadata": {},
   "source": [
    "`Benchmark the best algorithm by collecting statistics on the time performance at varying numbers of threads, workers, and partitions`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
